"""Automated claim extraction from evidence using GPT API."""

import json
import logging
import os
import time
from pathlib import Path
from typing import List, Dict, Any, Optional
from openai import OpenAI
from dotenv import load_dotenv

logger = logging.getLogger(__name__)

# Load environment variables
load_dotenv()

# Load path registry for alias normalization
_PATH_REGISTRY = None

def _load_path_registry() -> dict:
    """Load path registry from config file."""
    global _PATH_REGISTRY
    if _PATH_REGISTRY is None:
        registry_path = Path(__file__).parent.parent.parent / "config" / "path_registry_v2.json"
        if registry_path.exists():
            with open(registry_path, 'r') as f:
                _PATH_REGISTRY = json.load(f)
        else:
            _PATH_REGISTRY = {"path_aliases": {}, "paths": {}}
    return _PATH_REGISTRY

def normalize_path(path: str) -> str:
    """Normalize a claim path using path aliases from the registry.

    Args:
        path: The path generated by GPT (may be non-canonical)

    Returns:
        The canonical path if an alias exists, otherwise the original path
    """
    registry = _load_path_registry()
    aliases = registry.get("path_aliases", {})

    # Direct alias lookup
    if path in aliases:
        return aliases[path]

    # Try prefix matching for array paths (e.g., time_series[*].field)
    path_base = path.split('[')[0] if '[' in path else path
    if path_base in aliases:
        # Preserve array indices if present
        if '[' in path:
            suffix = path[len(path_base):]
            return aliases[path_base] + suffix
        return aliases[path_base]

    return path


EXTRACTION_PROMPT = """You are an intelligence analyst extracting structured claims from OSINT evidence about the Iran crisis.

INPUT: Evidence document with title, URL, and text content.

TASK: Extract 3-8 discrete, verifiable claims. Each claim MUST use one of the VALID PATHS listed below.

VALID PATHS (use ONLY these, with units in parentheses):
- current_state.casualties.protesters.killed.mid (integer, units: people)
- current_state.casualties.protesters.killed.low (integer, units: people)
- current_state.casualties.protesters.killed.high (integer, units: people)
- current_state.casualties.protesters.detained.estimate (integer, units: people)
- current_state.casualties.security_forces.killed.total (integer, units: people)
- current_state.protest_metrics.current_snapshot.intensity_trend (enum: ESCALATING, PLATEAUED, DECLINING; units: enum)
- current_state.protest_metrics.current_snapshot.cities_affected.value (integer, units: count)
- current_state.protest_metrics.current_snapshot.provinces_affected.value (integer, units: count)
- current_state.protest_metrics.protest_character.organizational_level (enum: SPONTANEOUS, LOOSELY_ORGANIZED, COORDINATED, HIGHLY_COORDINATED; units: enum)
- current_state.protest_metrics.protest_character.cross_class_coalition (enum: NONE, EMERGING, PARTIAL, BROAD; units: enum)
- current_state.information_environment.internet_status.current (enum: BLACKOUT, SEVERELY_DEGRADED, PARTIAL, FUNCTIONAL; units: enum)
- current_state.information_environment.internet_connectivity_index (number 0-100, units: percent)
- current_state.economic_conditions.rial_usd_rate.market (integer, units: count)
- current_state.economic_conditions.inflation.official_annual_percent (number, units: percent)
- current_situation.regime_response.crackdown_severity (enum: NONE, LIGHT, MODERATE, SEVERE, MASS_CASUALTY; units: enum)
- current_situation.regime_response.internet_shutdown (enum: NONE, PARTIAL, COMPLETE; units: enum)
- current_situation.regime_response.arrests (integer, units: count)
- current_situation.defections.confirmed_count (integer, units: count)
- external_actors.united_states.stated_position.quotes (string, units: text)

CLAIM STRUCTURE:
{{
  "claim_id": "CLM_YYYYMMDD_XXXX",
  "claim_class": "HARD_FACT",
  "path": "<one of the valid paths above>",
  "value": <appropriate type for the path>,
  "units": "<people|count|percent|enum|text - match exactly as shown above>",
  "as_of_utc": "2026-01-10T18:00:00Z",
  "source_doc_refs": [{{"doc_id": "{doc_id}", "quote": "relevant quote"}}],
  "source_grade": "B2",
  "confidence": "MEDIUM",
  "triangulated": false,
  "notes": "Brief explanation"
}}

CLAIM_CLASS VALUES:
- HARD_FACT: Verified factual claim (numbers, confirmed events)
- ESTIMATED: Numerical estimates with uncertainty
- ASSESSMENT: Analytical judgment or trend analysis

RULES:
1. ONLY use paths from the VALID PATHS list above
2. Use correct value types (integers for counts, enums in UPPERCASE)
3. Use EXACT units shown in parentheses above (people, count, percent, enum, text)
4. Skip claims that don't fit any valid path
5. Use unique claim_ids with incrementing numbers (0001, 0002, etc.)

EVIDENCE DOC:
{evidence_doc}

Extract claims now (return JSON object with "claims" array):"""


class ClaimExtractor:
    """Extract claims from evidence using GPT API."""

    def __init__(self, api_key: Optional[str] = None, model: str = "gpt-4o-mini"):
        """Initialize claim extractor with OpenAI API.

        Args:
            api_key: OpenAI API key (defaults to OPENAI_API_KEY env var)
            model: Model to use (default: gpt-4o-mini for cost efficiency and json_object support)
        """
        self.client = OpenAI(api_key=api_key or os.getenv('OPENAI_API_KEY'))
        self.model = model

    def extract_from_doc(self, evidence_doc: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Extract claims from a single evidence doc."""

        # Format evidence for prompt
        evidence_text = f"""
Title: {evidence_doc.get('title', 'Untitled')}
Source: {evidence_doc.get('organization', 'Unknown')}
URL: {evidence_doc.get('url', '')}
Published: {evidence_doc.get('published_at_utc', '')}
Language: {evidence_doc.get('language', 'en')}

Content:
{evidence_doc.get('raw_text', '')[:4000]}"""

        prompt = EXTRACTION_PROMPT.format(
            doc_id=evidence_doc.get('doc_id', ''),
            evidence_doc=evidence_text
        )

        max_attempts = 3
        last_error = None
        for attempt in range(1, max_attempts + 1):
            try:
                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=[{"role": "user", "content": prompt}],
                    temperature=0.1,
                    response_format={"type": "json_object"},
                    timeout=60,
                )

                claims_json = response.choices[0].message.content
                claims = json.loads(claims_json)

                # Ensure it's a list
                if isinstance(claims, dict) and 'claims' in claims:
                    claims = claims['claims']

                # Generate unique claim IDs using doc_id hash
                doc_id = evidence_doc.get('doc_id', 'UNKNOWN')
                # Use last 8 chars of doc_id to make unique IDs
                doc_hash = doc_id[-8:] if len(doc_id) >= 8 else doc_id

                for i, claim in enumerate(claims):
                    # Replace generic claim_id with unique one
                    claim['claim_id'] = f"CLM_{doc_hash}_{i+1:04d}"

                    # Normalize paths using registry aliases
                    if 'path' in claim:
                        original_path = claim['path']
                        claim['path'] = normalize_path(original_path)
                        if claim['path'] != original_path:
                            claim['_original_path'] = original_path

                return claims

            except Exception as e:
                last_error = e
                if attempt < max_attempts:
                    backoff = 2 ** attempt
                    logger.warning(
                        f"Attempt {attempt}/{max_attempts} failed for {evidence_doc.get('doc_id')}: {e}. "
                        f"Retrying in {backoff}s..."
                    )
                    time.sleep(backoff)
                else:
                    logger.exception(
                        f"All {max_attempts} attempts failed extracting claims from "
                        f"{evidence_doc.get('doc_id')}: {last_error}"
                    )

        return []

    def extract_from_jsonl(self, evidence_jsonl_path: str, output_path: str):
        """Extract claims from evidence_docs.jsonl."""
        total = 0

        with open(output_path, 'w') as out_f:
            with open(evidence_jsonl_path, 'r') as f:
                for line in f:
                    doc = json.loads(line)
                    logger.info(f"Extracting claims from {doc.get('doc_id')}...")
                    claims = self.extract_from_doc(doc)
                    for claim in claims:
                        out_f.write(json.dumps(claim) + '\n')
                    out_f.flush()
                    total += len(claims)
                    logger.info(f"  Extracted {len(claims)} claims")

        logger.info(f"Extracted {total} total claims -> {output_path}")


def main():
    """CLI entry point."""
    import argparse
    parser = argparse.ArgumentParser(description="Extract claims from evidence using GPT")
    parser.add_argument('--evidence', required=True, help="Path to evidence_docs.jsonl")
    parser.add_argument('--output', required=True, help="Path to output claims.jsonl")
    parser.add_argument('--model', default='gpt-4', help="OpenAI model to use")
    args = parser.parse_args()

    extractor = ClaimExtractor(model=args.model)
    extractor.extract_from_jsonl(args.evidence, args.output)


if __name__ == '__main__':
    main()
