# Documentation Index

Quick reference for all documentation files in this project.

---

## Start Here

ğŸ“„ **SUMMARY_FOR_USER_V2.md** (UPDATED POST-5.2 REVIEW)
- **Purpose:** Overview of what was built and how to use it
- **Read time:** 7 minutes
- **Audience:** You (project owner)
- **Status:** Clarifies MVP-ready vs production-ready, Mode 1 vs Mode 2
- **Next steps:** Choose which document to read based on your goal

ğŸ“„ **SUMMARY_FOR_USER.md** (SUPERSEDED)
- **Status:** Original version; now outdated. See V2 above.

---

## For Understanding the System

ğŸ“„ **DIAGRAM.txt** (Visual Overview)
- **Purpose:** ASCII art architecture diagram
- **Read time:** 5 minutes
- **Audience:** Visual learners, quick reference
- **Contents:** Data flow, key components, innovations

ğŸ“„ **ARCHITECTURE.md** (Complete Technical Docs)
- **Purpose:** Full system architecture documentation
- **Read time:** 30 minutes
- **Audience:** Technical readers, AI reviewers, future developers
- **Contents:** Layer-by-layer breakdown, design decisions, bugs fixed, testing, performance

ğŸ“„ **README.md** (User Guide)
- **Purpose:** How to use the simulator (original docs)
- **Read time:** 10 minutes
- **Audience:** End users
- **Contents:** Installation, workflow, outputs, limitations

ğŸ“„ **EVIDENCE_BUNDLE_SPEC.md** (NEW)
- **Purpose:** Deep Research bundle format specification
- **Read time:** 15 minutes
- **Audience:** Data engineers, Deep Research users
- **Contents:** Schema, validation rules, examples, fail-fast rules

ğŸ“„ **CLAUDE.md** (Claude Code Instructions)
- **Purpose:** Instructions for Claude Code when working on this project
- **Read time:** 5 minutes
- **Audience:** Claude Code (me)
- **Contents:** Agent architecture, my tasks, principles

---

## For Sharing with Others

ğŸ“„ **REVIEW_FOR_OPUS.md** (For Opus 4.5 Critique)
- **Purpose:** Request architectural review from Claude Opus 4.5
- **Read time:** 20 minutes (to read), indefinite (for Opus to respond)
- **Audience:** Claude Opus 4.5 (or other expert reviewers)
- **Contents:**
  - Executive summary
  - 20 specific questions
  - Code review requests
  - Current results
- **How to use:** Upload to Opus 4.5 and ask for critique

---

## For Ongoing Work

ğŸ“„ **WORKFLOW_UPDATE.md** (Deep Research Integration)
- **Purpose:** How to update simulation with new intelligence
- **Read time:** 15 minutes
- **Audience:** You (when you have new Deep Research results)
- **Contents:**
  - Step-by-step update process
  - What Claude Code does automatically
  - Example change reports
  - Interactive refinement
  - FAQ

---

## Code Documentation

ğŸ“ **src/simulation.py** (913 lines)
- Core Monte Carlo engine
- State machine, window enforcement, daily simulation loop

ğŸ“ **src/priors/contract.py** (180 lines)
- Priors resolver and validator
- Time semantics enforcement
- QA report generation

ğŸ“ **src/pipeline/** (253 lines)
- models.py: Evidence/Claims data structures
- compile_intel.py: Claims compiler
- qa.py: Quality gates

ğŸ“ **tests/test_time_semantics.py** (111 lines)
- 6 unit tests (all passing)
- Window logic, anchor tracking, condition checks

ğŸ“ **src/forecasting/** (Oracle Layer - v3.0)
- `catalog.py`: Event catalog loading, validation, filtering
- `bins.py`: Bin validation and value-to-bin mapping (346 lines)
- `forecast.py`: Forecast generation, distribution validation
- `resolver.py`: Resolution logic with bin_map/enum_match rules
- `ledger.py`: Append-only JSONL storage
- `evidence.py`: Evidence snapshot storage with hashing
- `scorer.py`: Brier/log scoring

ğŸ“ **tests/test_bins.py** (289 lines)
- 24 tests for bin validation and value mapping

ğŸ“ **tests/test_catalog_v3.py** (379 lines)
- 26 tests for v3.0.0 schema and event filtering

ğŸ“ **tests/test_forecast_validation.py** (206 lines)
- 18 tests for distribution validation

ğŸ“ **tests/test_resolver_bins.py** (284 lines)
- 18 tests for bin_map and enum_match rules

---

## Prompts

ğŸ“ **prompts/01_research_prompt.md**
- Deep Research query for intelligence gathering
- Use to generate `iran_crisis_intel.json`

ğŸ“ **prompts/02_security_analyst_prompt.md**
- Security Analyst Agent prompt
- Use to generate `analyst_priors.json`
- **v2.1:** Now includes ACH (Analysis of Competing Hypotheses) and pre-mortem analysis

ğŸ“ **prompts/03_deep_research_source_gathering.md**
- Deep Research evidence collection prompt
- **v2.1:** Includes Evidence Quality Gate (grade B3 threshold)

ğŸ“ **prompts/05_red_team_prompt.md** - NEW v2.1
- Devil's advocate review of analyst priors (~12KB)
- Challenges overconfident estimates
- Proposes specific numeric revisions

---

## Data Files

ğŸ“ **data/iran_crisis_intel.json**
- Structured intelligence data
- Source-graded, timestamped
- Currently: placeholder values

ğŸ“ **data/analyst_priors.json**
- Probability estimates with time semantics
- Generated by Security Analyst Agent
- Currently: placeholder values

---

## Output Files

ğŸ“ **outputs/simulation_results.json**
- Latest simulation run results
- Outcome distribution, event rates, sample trajectories

ğŸ“ **outputs/priors_resolved.json**
- Priors with defaults filled in
- Emitted by contract resolver

ğŸ“ **outputs/priors_qa.json**
- QA report (errors and warnings)
- Status: OK (0 errors, 3 warnings)

---

## Quick Reference by Goal

### Goal: "I want to understand what was built"
â†’ Start with **DIAGRAM.txt** (5 min), then **ARCHITECTURE.md** (30 min)

### Goal: "I want to get expert feedback"
â†’ Share **REVIEW_FOR_OPUS.md** with Claude Opus 4.5

### Goal: "I have new intelligence data"
â†’ Read **WORKFLOW_UPDATE.md**, then provide data to Claude Code

### Goal: "I want to run the simulation"
â†’ Read **README.md** for usage instructions

### Goal: "I want to understand the code"
â†’ Read **ARCHITECTURE.md** sections 2-3, then dive into `src/simulation.py`

### Goal: "I want to extend the system"
â†’ Read **ARCHITECTURE.md** "Extension Points" section

### Goal: "I want to know if this is production-ready"
â†’ Read **ARCHITECTURE.md** "Acceptance Criteria" and "Testing Strategy"

---

## File Sizes

```
Document                    Lines    Purpose
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SUMMARY_FOR_USER.md          ~300    Overview for you
DIAGRAM.txt                  ~200    Visual architecture
ARCHITECTURE.md            ~1,200    Complete technical docs
REVIEW_FOR_OPUS.md           ~900    Review request for Opus 4.5
WORKFLOW_UPDATE.md           ~600    Update guide
README.md                    ~180    User guide (original)
CLAUDE.md                    ~180    Claude Code instructions
DOCS_INDEX.md                  ~80    This file
                           â”€â”€â”€â”€â”€â”€
                           ~3,640    Total documentation lines
```

---

## Documentation Quality Checklist

âœ… **Comprehensive:** All major system components documented
âœ… **Accessible:** Multiple entry points (visual, technical, practical)
âœ… **Actionable:** Clear next steps for different goals
âœ… **Auditable:** Design decisions explained with rationale
âœ… **Shareable:** Formatted for AI review (Opus 4.5)
âœ… **Maintainable:** Index and cross-references

---

## New in v3.0 (Oracle Phase 3A)

- âœ… **Multi-Outcome Events** - Support for binned_continuous and categorical event types
- âœ… **Bin Validation** - `src/forecasting/bins.py` for bin spec validation and value mapping
- âœ… **Event Catalog v3.0.0** - 18 events (5 forecastable, 5 diagnostic, 8 disabled)
- âœ… **Baseline Forecasters** - baseline_climatology and baseline_persistence forecast sources
- âœ… **New Resolution Rules** - bin_map for binned events, enum_match for categorical
- âœ… **Distribution Validation** - Probability sum/key validation in `forecast.py`
- âœ… **Event Filtering** - `get_forecastable_events()` filters by enabled flag
- âœ… **Manual Resolution Queue** - Events with `requires_manual_resolution: true` skip auto-resolve

## New in v2.1

- âœ… **Red Team Agent** - Devil's advocate review of analyst priors (`prompts/05_red_team_prompt.md`)
- âœ… **Sensitivity Analysis** - Automated parameter sensitivity testing (`scripts/sensitivity_analysis.py`)
- âœ… **ACH Pre-Mortem** - Analysis of Competing Hypotheses in Security Analyst prompt
- âœ… **Evidence Quality Gate** - Source grade thresholds in Deep Research prompt
- âœ… **Feedback Loops** - Concession/defection dampening in simulation
- âœ… **Tail Risk Labels** - Visual indicators for low-probability outcomes
- âœ… **Regional Cascade** - Bidirectional Iran/Iraq/Syria stability modeling

## What's Not Documented (Yet)

âœ… ~~Sensitivity analysis methodology~~ - Now documented (v2.1)
âœ… ~~Regional cascade implementation~~ - Now built and documented (v2.1)
âŒ Calibration scoring (requires ground truth)
âŒ Real-world case studies (placeholder data)
âŒ API documentation (if building web interface)

---

## Suggested Reading Order

**For first-time readers:**
1. SUMMARY_FOR_USER.md (this is you)
2. DIAGRAM.txt (quick visual)
3. README.md (how to use)
4. ARCHITECTURE.md (deep dive)

**For reviewers (Opus 4.5):**
1. REVIEW_FOR_OPUS.md (targeted questions)
2. ARCHITECTURE.md (context)
3. src/simulation.py (code)

**For ongoing work:**
1. WORKFLOW_UPDATE.md (when new intel arrives)
2. README.md (reference for commands)
3. outputs/priors_qa.json (check for issues)

---

## Maintenance

**When to update documentation:**
- Major architectural changes â†’ Update ARCHITECTURE.md
- New features â†’ Update README.md
- Code refactoring â†’ Update inline comments
- Bug fixes â†’ Update ARCHITECTURE.md "Bugs Fixed" section
- New questions for Opus â†’ Update REVIEW_FOR_OPUS.md

**Version control:**
- Tag major doc updates: `git tag -a docs-v1.0 -m "Initial complete documentation"`
- Keep docs in sync with code (CI check?)

---

**Last Updated:** 2026-01-19
**Status:** Complete and current (v3.0 Oracle Phase 3A documented)
**Next Review:** After Phase 3B scoring implementation
